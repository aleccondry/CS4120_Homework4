{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4: Sentiment Analysis - Task 2\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: Alec Condry (4120) and Shrihari Subramaniam (4120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Train a Naive Bayes Model (30 points)\n",
    "----\n",
    "\n",
    "Using `nltk`'s `NaiveBayesClassifier` class, train a Naive Bayes classifier using a Bag of Words as features.\n",
    "https://www.nltk.org/_modules/nltk/classify/naivebayes.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alecc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# our utility functions\n",
    "# RESTART your jupyter notebook kernel if you make changes to this file\n",
    "import sentiment_utils as sutils\n",
    "\n",
    "# nltk for Naive Bayes and metrics\n",
    "import nltk\n",
    "import nltk.classify.util\n",
    "from nltk.metrics.scores import (precision, recall, f_measure, accuracy)\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "# some potentially helpful data structures from collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# so that we can make plots\n",
    "import matplotlib.pyplot as plt\n",
    "# if you want to use seaborn to make plots\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants for the files we are using\n",
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "DEV_FILE = \"movie_reviews_dev.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in your data and make sure you understand the format\n",
    "# Do not print out too much so as to impede readability of your notebook\n",
    "train_tups = sutils.generate_tuples_from_file(TRAIN_FILE)\n",
    "dev_tups = sutils.generate_tuples_from_file(DEV_FILE)\n",
    "\n",
    "# [[list of tokens], label] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1])\n",
      "class 0: 0.8574938669515418\n",
      "class 1: 0.1425061330484529\n",
      "Classified as negative\n"
     ]
    }
   ],
   "source": [
    "# set up a sentiment classifier using NLTK's NaiveBayesClassifier and \n",
    "# a bag of words as features\n",
    "# take a look at the function in lecture notebook 7 (feel free to copy + paste that function)\n",
    "# the nltk classifier expects a dictionary of features as input where the key is the feature name\n",
    "# and the value is the feature value\n",
    "\n",
    "\n",
    "# need to return a dict to work with the NLTK classifier\n",
    "# Possible problem for students: evaluate the difference \n",
    "# between using binarized features and using counts (non binarized features)\n",
    "def word_feats(words):\n",
    "    \"\"\"\n",
    "    This function converts a list of words so that they are featurized\n",
    "    for nltk's format for bag-of-words\n",
    "    Parameters:\n",
    "    words - list of words where each element is a single word \n",
    "    Returns: dict mapping every word to True\n",
    "    \"\"\"\n",
    "    return dict([(word, True) for word in words]) \n",
    "\n",
    "# set up & train a sentiment classifier using NLTK's NaiveBayesClassifier and\n",
    "# classify the first example in the dev set as an example\n",
    "# make sure your output is well-labeled\n",
    "# Should take < 10 sec to train (on Felix's computer this takes 0.5 sec)\n",
    "vocab = set([token for review in train_tups[0] for token in review])\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Multinomial\n",
    "featuresets = []\n",
    "for review, label in zip(train_tups[0], train_tups[1]):\n",
    "    counts = dict(Counter(review))\n",
    "    featuresets.append((counts, label))\n",
    "\n",
    "# Binomial\n",
    "\n",
    "\n",
    "# test to make sure that you can train the classifier and use it to classify a new example\n",
    "classifier = NaiveBayesClassifier.train(featuresets)\n",
    "featurized_example = word_feats(dev_tups[0][0])\n",
    "print(classifier.prob_classify(featurized_example).samples())  # will tell you what classes are available\n",
    "print(f\"class 0: {classifier.prob_classify(featurized_example).prob(0)}\")  # get the probability for class '0'\n",
    "print(f\"class 1: {classifier.prob_classify(featurized_example).prob(1)}\")  # get the probability for class '1'\n",
    "print(f\"Classified as {'positive' if classifier.classify(word_feats(review)) == 1 else 'negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n",
      "Precision = 0.42\n",
      "Recall =    0.417910447761194\n",
      "f1 score =  0.4189526184538653\n",
      "Accuracy =  0.835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42, 0.417910447761194, 0.4189526184538653, 0.835)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using the provided dev set, evaluate your model with precision, recall, and f1 score as well as accuracy\n",
    "# You may use nltk's implemented `precision`, `recall`, `f_measure`, and `accuracy` functions\n",
    "# (make sure to look at the documentation for these functions!)\n",
    "# you will be creating a similar graph for logistic regression and neural nets, so make sure\n",
    "# you use functions wisely so that you do not have excessive repeated code\n",
    "# write any helper functions you need in sentiment_utils.py (functions that you'll use in your other notebooks as well)\n",
    "preds = []\n",
    "for review in dev_tups[0]:\n",
    "    class_result = classifier.classify(word_feats(review))\n",
    "    preds.append(class_result)\n",
    "sutils.get_prfa(dev_tups[1], preds, verbose=True)\n",
    "    \n",
    "# create a graph of your classifier's performance on the dev set as a function of the amount of training data\n",
    "# the x-axis should be the amount of training data (as a percentage of the total training data)\n",
    "# the y-axis should be the performance of the classifier on the dev set\n",
    "# the graph should have 4 lines, one for each of precision, recall, f1, and accuracy\n",
    "# the graph should have a legend, title, and axis labels\n",
    "\n",
    "# takes approximately 3.5sec to run on Felix's computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your model using both a __binarized__ and a __multinomial__ BoW. Use whichever one gives you a better final f1 score on the dev set to produce your graphs.\n",
    "\n",
    "- f1 score binarized: __YOUR ANSWER HERE__\n",
    "- f1 score multinomial: __YOUR ANSWER HERE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
